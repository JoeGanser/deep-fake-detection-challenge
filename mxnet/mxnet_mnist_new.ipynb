{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************************\n",
    "Make sure you are using the `conda_python3` Jupyter Kernel.\n",
    "We will install the necessary libraries.\n",
    "*****************************\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and hosting SageMaker Models using the Apache MXNet Module API\n",
    "\n",
    "The **SageMaker Python SDK** makes it easy to train and deploy MXNet models. In this example, we train a simple neural network using the Apache MXNet [Module API](https://mxnet.apache.org/api/python/module/module.html) and the MNIST dataset. The MNIST dataset is widely used for handwritten digit classification, and consists of 70,000 labeled 28x28 pixel grayscale images of hand-written digits. The dataset is split into 60,000 training images and 10,000 test images. There are 10 classes (one for each of the 10 digits). The task at hand is to train a model using the 60,000 training images and subsequently test its classification accuracy on the 10,000 test images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First we need to define a few variables that will be needed later in the example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install MXNet and SageMaker\n",
    "_Note:  Ignore Warnings and Errors Below_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling mxnet-1.5.1:\n",
      "  Successfully uninstalled mxnet-1.5.1\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y mxnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mSkipping mxnet as it is not installed.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 uninstall -y mxnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mxnet==1.5.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/57/549a1ac1179c9d590cd8fa1c8b4c6bdeb581139f65e3790812c81ae98bbf/mxnet-1.5.1-py2.py3-none-manylinux1_x86_64.whl (23.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 23.1MB 111.2MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting graphviz<0.9.0,>=0.8.1 (from mxnet==1.5.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
      "Collecting requests<3,>=2.20.0 (from mxnet==1.5.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 75.4MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting numpy<2.0.0,>1.16.0 (from mxnet==1.5.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/e6/45f71bd24f4e37629e9db5fb75caab919507deae6a5a257f9e4685a5f931/numpy-1.18.0-cp36-cp36m-manylinux1_x86_64.whl (20.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 20.1MB 108.7MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting chardet<3.1.0,>=3.0.2 (from requests<3,>=2.20.0->mxnet==1.5.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl (133kB)\n",
      "\u001b[K    100% |████████████████████████████████| 143kB 113.2MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting certifi>=2017.4.17 (from requests<3,>=2.20.0->mxnet==1.5.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/63/df50cac98ea0d5b006c55a399c3bf1db9da7b5a24de7890bc9cfd5dd9e99/certifi-2019.11.28-py2.py3-none-any.whl (156kB)\n",
      "\u001b[K    100% |████████████████████████████████| 163kB 114.0MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 (from requests<3,>=2.20.0->mxnet==1.5.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/40/a9837291310ee1ccc242ceb6ebfd9eb21539649f193a7c8c86ba15b98539/urllib3-1.25.7-py2.py3-none-any.whl (125kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 110.7MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting idna<2.9,>=2.5 (from requests<3,>=2.20.0->mxnet==1.5.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 77.5MB/s ta 0:00:01\n",
      "\u001b[31mtensorflow 2.0.0 has requirement gast==0.2.2, but you'll have gast 0.3.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mtensorflow 2.0.0 has requirement tensorboard<2.1.0,>=2.0.0, but you'll have tensorboard 2.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mcoremltools 2.0 has requirement six==1.10.0, but you'll have six 1.13.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mawscli 1.16.76 has requirement botocore==1.12.66, but you'll have botocore 1.13.46 which is incompatible.\u001b[0m\n",
      "\u001b[31mawscli 1.16.76 has requirement rsa<=3.5.0,>=3.1.2, but you'll have rsa 4.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mawscli 1.16.76 has requirement s3transfer<0.2.0,>=0.1.12, but you'll have s3transfer 0.2.1 which is incompatible.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: graphviz, chardet, certifi, urllib3, idna, requests, numpy, mxnet\n",
      "\u001b[31mCould not install packages due to an EnvironmentError: [Errno 13] Permission denied: '/usr/lib/python3.6/dist-packages/graphviz/dot.py'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\u001b[0m\n",
      "\u001b[33mYou are using pip version 19.0.2, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install mxnet==1.5.1 --upgrade --ignore-installed --no-cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sagemaker\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/af/9f4c8faf81faee2d51ef4bd91f2e081f1a8f3ea2ae28836ac2cfd00d333f/sagemaker-1.50.0.tar.gz (291kB)\n",
      "\u001b[K    100% |████████████████████████████████| 296kB 59.4MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting boto3>=1.10.32 (from sagemaker)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/f9/9798c5221d45b637ae1f42f0e0467e3bdfc3af46769b6bc7a29d93b2ecf6/boto3-1.10.46-py2.py3-none-any.whl (128kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 84.0MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.9.0 (from sagemaker)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/e6/45f71bd24f4e37629e9db5fb75caab919507deae6a5a257f9e4685a5f931/numpy-1.18.0-cp36-cp36m-manylinux1_x86_64.whl (20.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 20.1MB 109.3MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting protobuf>=3.1 (from sagemaker)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/ac/838c8c8a5f33a58132dd2ad2a30329f6ae1614a9f56ffb79eaaf71a9d156/protobuf-3.11.2-cp36-cp36m-manylinux1_x86_64.whl (1.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.3MB 115.8MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=0.19.0 (from sagemaker)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dc/29/162476fd44203116e7980cfbd9352eef9db37c49445d1fec35509022f6aa/scipy-1.4.1-cp36-cp36m-manylinux1_x86_64.whl (26.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 26.1MB 109.0MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting protobuf3-to-dict>=0.1.5 (from sagemaker)\n",
      "  Downloading https://files.pythonhosted.org/packages/6b/55/522bb43539fed463275ee803d79851faaebe86d17e7e3dbc89870d0322b9/protobuf3-to-dict-0.1.5.tar.gz\n",
      "Collecting requests<3,>=2.20.0 (from sagemaker)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 70.6MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting smdebug-rulesconfig==0.1.2 (from sagemaker)\n",
      "  Downloading https://files.pythonhosted.org/packages/36/08/b0d1d30f5c1e11a2d12af3b940cf5673dc5bbb67517d815807ae855abc5e/smdebug_rulesconfig-0.1.2-py2.py3-none-any.whl\n",
      "Collecting jmespath<1.0.0,>=0.7.1 (from boto3>=1.10.32->sagemaker)\n",
      "  Downloading https://files.pythonhosted.org/packages/83/94/7179c3832a6d45b266ddb2aac329e101367fbdb11f425f13771d27f225bb/jmespath-0.9.4-py2.py3-none-any.whl\n",
      "Collecting botocore<1.14.0,>=1.13.46 (from boto3>=1.10.32->sagemaker)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/17/40f9fb50219e8a24fd9c09c909d26f074d4a2fc83b66065dff3770ecbebb/botocore-1.13.46-py2.py3-none-any.whl (5.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 5.9MB 111.9MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting s3transfer<0.3.0,>=0.2.0 (from boto3>=1.10.32->sagemaker)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/8a/1fc3dba0c4923c2a76e1ff0d52b305c44606da63f718d14d3231e21c51b0/s3transfer-0.2.1-py2.py3-none-any.whl (70kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 72.4MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting six>=1.9 (from protobuf>=3.1->sagemaker)\n",
      "  Downloading https://files.pythonhosted.org/packages/65/26/32b8464df2a97e6dd1b656ed26b2c194606c16fe163c695a992b36c11cdf/six-1.13.0-py2.py3-none-any.whl\n",
      "Collecting setuptools (from protobuf>=3.1->sagemaker)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/d3/955738b20d3832dfa3cd3d9b07e29a8162edb480bf988332f5e6e48ca444/setuptools-44.0.0-py2.py3-none-any.whl (583kB)\n",
      "\u001b[K    100% |████████████████████████████████| 583kB 112.3MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 (from requests<3,>=2.20.0->sagemaker)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/40/a9837291310ee1ccc242ceb6ebfd9eb21539649f193a7c8c86ba15b98539/urllib3-1.25.7-py2.py3-none-any.whl (125kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 111.0MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting idna<2.9,>=2.5 (from requests<3,>=2.20.0->sagemaker)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 81.4MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting chardet<3.1.0,>=3.0.2 (from requests<3,>=2.20.0->sagemaker)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl (133kB)\n",
      "\u001b[K    100% |████████████████████████████████| 143kB 118.0MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting certifi>=2017.4.17 (from requests<3,>=2.20.0->sagemaker)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/63/df50cac98ea0d5b006c55a399c3bf1db9da7b5a24de7890bc9cfd5dd9e99/certifi-2019.11.28-py2.py3-none-any.whl (156kB)\n",
      "\u001b[K    100% |████████████████████████████████| 163kB 112.9MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" (from botocore<1.14.0,>=1.13.46->boto3>=1.10.32->sagemaker)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl (227kB)\n",
      "\u001b[K    100% |████████████████████████████████| 235kB 113.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting docutils<0.16,>=0.10 (from botocore<1.14.0,>=1.13.46->boto3>=1.10.32->sagemaker)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/cd/a6aa959dca619918ccb55023b4cb151949c64d4d5d55b3f4ffd7eee0c6e8/docutils-0.15.2-py3-none-any.whl (547kB)\n",
      "\u001b[K    100% |████████████████████████████████| 552kB 113.7MB/s ta 0:00:01\n",
      "\u001b[31mtensorflow 2.0.0 has requirement gast==0.2.2, but you'll have gast 0.3.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mtensorflow 2.0.0 has requirement tensorboard<2.1.0,>=2.0.0, but you'll have tensorboard 2.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mcoremltools 2.0 has requirement six==1.10.0, but you'll have six 1.13.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mawscli 1.16.76 has requirement botocore==1.12.66, but you'll have botocore 1.13.46 which is incompatible.\u001b[0m\n",
      "\u001b[31mawscli 1.16.76 has requirement rsa<=3.5.0,>=3.1.2, but you'll have rsa 4.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mawscli 1.16.76 has requirement s3transfer<0.2.0,>=0.1.12, but you'll have s3transfer 0.2.1 which is incompatible.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: jmespath, six, python-dateutil, docutils, urllib3, botocore, s3transfer, boto3, numpy, setuptools, protobuf, scipy, protobuf3-to-dict, idna, chardet, certifi, requests, smdebug-rulesconfig, sagemaker\n",
      "\u001b[33m  The scripts f2py, f2py3 and f2py3.6 are installed in '/home/ec2-user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "  Running setup.py install for protobuf3-to-dict ... \u001b[?25ldone\n",
      "\u001b[33m  The script chardetect is installed in '/home/ec2-user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[?25h  Running setup.py install for sagemaker ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed boto3-1.10.46 botocore-1.13.46 certifi-2019.11.28 chardet-3.0.4 docutils-0.15.2 idna-2.8 jmespath-0.9.4 numpy-1.18.0 protobuf-3.11.2 protobuf3-to-dict-0.1.5 python-dateutil-2.8.1 requests-2.22.0 s3transfer-0.2.1 sagemaker-1.50.0 scipy-1.4.1 setuptools-44.0.0 six-1.13.0 smdebug-rulesconfig-0.1.2 urllib3-1.25.7\n",
      "\u001b[33mYou are using pip version 19.0.2, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install sagemaker --upgrade --ignore-installed --no-cache --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install requests==2.20.1 --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restart the Kernel to Recognize New Dependencies Above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display_html\n",
    "display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\", raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the SageMaker Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "isConfigCell": true
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the Service Execution Role and Region\n",
    "Get IAM role arn used to give training and hosting access to your data.  See the documentation for how to create these.  Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the `sagemaker.get_execution_role()` with a the appropriate full IAM role arn string(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 bucket for saving code and model artifacts.\n",
    "# Feel free to specify a different bucket here if you wish.\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "# Location to save your custom code in tar.gz format.\n",
    "custom_code_upload_location = 's3://{}/customcode/mxnet'.format(bucket)\n",
    "\n",
    "# Location where results of model training are saved.\n",
    "model_artifacts_location = 's3://{}/artifacts'.format(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoleARN:  arn:aws:iam::835319576252:role/service-role/AmazonSageMaker-ExecutionRole-20191006T135881\n",
      "\n",
      "Region:  us-east-1\n"
     ]
    }
   ],
   "source": [
    "role = get_execution_role()\n",
    "print('RoleARN:  {}\\n'.format(role))\n",
    "\n",
    "region = sagemaker_session.boto_session.region_name\n",
    "print('Region:  {}'.format(region))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The training script\n",
    "\n",
    "The ``mnist_mxnet.py`` script provides all the code we need for training and hosting a SageMaker model. The script also checkpoints the model at the end of every epoch and saves the model graph, params and optimizer state in the folder `/opt/ml/checkpoints`. If the folder path does not exist then it will skip checkpointing. The script we will use is adaptated from Apache MXNet [MNIST tutorial (https://mxnet.incubator.apache.org/tutorials/python/mnist.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import argparse\r\n",
      "import gzip\r\n",
      "import json\r\n",
      "import logging\r\n",
      "import os\r\n",
      "import struct\r\n",
      "\r\n",
      "import mxnet as mx\r\n",
      "import numpy as np\r\n",
      "\r\n",
      "\r\n",
      "def load_data(path):\r\n",
      "    with gzip.open(find_file(path, \"labels.gz\")) as flbl:\r\n",
      "        struct.unpack(\">II\", flbl.read(8))\r\n",
      "        labels = np.fromstring(flbl.read(), dtype=np.int8)\r\n",
      "    with gzip.open(find_file(path, \"images.gz\")) as fimg:\r\n",
      "        _, _, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\r\n",
      "        images = np.fromstring(fimg.read(), dtype=np.uint8).reshape(len(labels), rows, cols)\r\n",
      "        images = images.reshape(images.shape[0], 1, 28, 28).astype(np.float32) / 255\r\n",
      "    return labels, images\r\n",
      "\r\n",
      "\r\n",
      "def find_file(root_path, file_name):\r\n",
      "    for root, dirs, files in os.walk(root_path):\r\n",
      "        if file_name in files:\r\n",
      "            return os.path.join(root, file_name)\r\n",
      "\r\n",
      "\r\n",
      "def build_graph():\r\n",
      "    data = mx.sym.var('data')\r\n",
      "    data = mx.sym.flatten(data=data)\r\n",
      "    fc1 = mx.sym.FullyConnected(data=data, num_hidden=128)\r\n",
      "    act1 = mx.sym.Activation(data=fc1, act_type=\"relu\")\r\n",
      "    fc2 = mx.sym.FullyConnected(data=act1, num_hidden=64)\r\n",
      "    act2 = mx.sym.Activation(data=fc2, act_type=\"relu\")\r\n",
      "    fc3 = mx.sym.FullyConnected(data=act2, num_hidden=10)\r\n",
      "    return mx.sym.SoftmaxOutput(data=fc3, name='softmax')\r\n",
      "\r\n",
      "\r\n",
      "def get_training_context(num_gpus):\r\n",
      "    if num_gpus:\r\n",
      "        return [mx.gpu(i) for i in range(num_gpus)]\r\n",
      "    else:\r\n",
      "        return mx.cpu()\r\n",
      "\r\n",
      "\r\n",
      "def train(batch_size, epochs, learning_rate, num_gpus, training_channel, testing_channel,\r\n",
      "          hosts, current_host, model_dir):\r\n",
      "    (train_labels, train_images) = load_data(training_channel)\r\n",
      "    (test_labels, test_images) = load_data(testing_channel)\r\n",
      "    CHECKPOINTS_DIR = '/opt/ml/checkpoints'\r\n",
      "    checkpoints_enabled = os.path.exists(CHECKPOINTS_DIR)\r\n",
      "\r\n",
      "    # Data parallel training - shard the data so each host\r\n",
      "    # only trains on a subset of the total data.\r\n",
      "    shard_size = len(train_images) // len(hosts)\r\n",
      "    for i, host in enumerate(hosts):\r\n",
      "        if host == current_host:\r\n",
      "            start = shard_size * i\r\n",
      "            end = start + shard_size\r\n",
      "            break\r\n",
      "\r\n",
      "    train_iter = mx.io.NDArrayIter(train_images[start:end], train_labels[start:end], batch_size,\r\n",
      "                                   shuffle=True)\r\n",
      "    val_iter = mx.io.NDArrayIter(test_images, test_labels, batch_size)\r\n",
      "\r\n",
      "    logging.getLogger().setLevel(logging.DEBUG)\r\n",
      "\r\n",
      "    kvstore = 'local' if len(hosts) == 1 else 'dist_sync'\r\n",
      "\r\n",
      "    mlp_model = mx.mod.Module(symbol=build_graph(),\r\n",
      "                              context=get_training_context(num_gpus))\r\n",
      "\r\n",
      "    checkpoint_callback = None\r\n",
      "    if checkpoints_enabled:\r\n",
      "        # Create a checkpoint callback that checkpoints the model params and the optimizer state after every epoch at the given path.\r\n",
      "        checkpoint_callback = mx.callback.module_checkpoint(mlp_model,\r\n",
      "                                                            CHECKPOINTS_DIR + \"/mnist\",\r\n",
      "                                                            period=1,\r\n",
      "                                                            save_optimizer_states=True)\r\n",
      "    mlp_model.fit(train_iter,\r\n",
      "                  eval_data=val_iter,\r\n",
      "                  kvstore=kvstore,\r\n",
      "                  optimizer='sgd',\r\n",
      "                  optimizer_params={'learning_rate': learning_rate},\r\n",
      "                  eval_metric='acc',\r\n",
      "                  epoch_end_callback = checkpoint_callback,\r\n",
      "                  batch_end_callback=mx.callback.Speedometer(batch_size, 100),\r\n",
      "                  num_epoch=epochs)\r\n",
      "\r\n",
      "    if current_host == hosts[0]:\r\n",
      "        save(model_dir, mlp_model)\r\n",
      "\r\n",
      "\r\n",
      "def save(model_dir, model):\r\n",
      "    model.symbol.save(os.path.join(model_dir, 'model-symbol.json'))\r\n",
      "    model.save_params(os.path.join(model_dir, 'model-0000.params'))\r\n",
      "\r\n",
      "    signature = [{'name': data_desc.name, 'shape': [dim for dim in data_desc.shape]}\r\n",
      "                 for data_desc in model.data_shapes]\r\n",
      "    with open(os.path.join(model_dir, 'model-shapes.json'), 'w') as f:\r\n",
      "        json.dump(signature, f)\r\n",
      "\r\n",
      "\r\n",
      "def parse_args():\r\n",
      "    parser = argparse.ArgumentParser()\r\n",
      "\r\n",
      "    parser.add_argument('--batch-size', type=int, default=100)\r\n",
      "    parser.add_argument('--epochs', type=int, default=10)\r\n",
      "    parser.add_argument('--learning-rate', type=float, default=0.1)\r\n",
      "\r\n",
      "    parser.add_argument('--model-dir', type=str, default=os.environ['SM_MODEL_DIR'])\r\n",
      "    parser.add_argument('--train', type=str, default=os.environ['SM_CHANNEL_TRAIN'])\r\n",
      "    parser.add_argument('--test', type=str, default=os.environ['SM_CHANNEL_TEST'])\r\n",
      "\r\n",
      "    parser.add_argument('--current-host', type=str, default=os.environ['SM_CURRENT_HOST'])\r\n",
      "    parser.add_argument('--hosts', type=list, default=json.loads(os.environ['SM_HOSTS']))\r\n",
      "\r\n",
      "    return parser.parse_args()\r\n",
      "\r\n",
      "if __name__ == '__main__':\r\n",
      "    args = parse_args()\r\n",
      "    num_gpus = int(os.environ['SM_NUM_GPUS'])\r\n",
      "\r\n",
      "    train(args.batch_size, args.epochs, args.learning_rate, num_gpus, args.train, args.test,\r\n",
      "          args.hosts, args.current_host, args.model_dir)\r\n"
     ]
    }
   ],
   "source": [
    "!cat ./src/mnist_mxnet.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker's MXNet Estimator Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SageMaker ```MXNet``` estimator allows us to run single machine or distributed training in SageMaker, using CPU or GPU-based instances.\n",
    "\n",
    "When we create the estimator, we pass in the filename of our training script, the name of our IAM execution role, and the S3 locations we defined in the setup section. We also provide a few other parameters. ``train_instance_count`` and ``train_instance_type`` determine the number and type of SageMaker instances that will be used for the training job. The ``hyperparameters`` parameter is a ``dict`` of values that will be passed to your training script -- you can see how to access these values in the ``mnist.py`` script above.\n",
    "\n",
    "For this example, we will choose one ``ml.m4.xlarge`` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.mxnet import MXNet\n",
    "\n",
    "mnist_estimator = MXNet(entry_point='mnist_mxnet.py',\n",
    "                        source_dir='./src',\n",
    "                        role=role,\n",
    "                        output_path=model_artifacts_location,\n",
    "                        code_location=custom_code_upload_location,\n",
    "                        train_instance_count=1,\n",
    "                        train_instance_type='ml.m4.xlarge',\n",
    "                        framework_version='1.4.1',\n",
    "                        py_version='py3',\n",
    "                        distributions={'parameter_server': {'enabled': True}},\n",
    "                        hyperparameters={'learning-rate': 0.1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Training Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we've constructed our MXNet object, we can fit it using data stored in S3. Below we run SageMaker training on two input channels: **train** and **test**.\n",
    "\n",
    "During training, SageMaker makes this data stored in S3 available in the local filesystem where the mnist script is running. The ```mnist.py``` script simply loads the train and test data from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_job_name:  mxnet-training-2020-01-06-18-54-07-615\n",
      "CPU times: user 34.9 ms, sys: 4.56 ms, total: 39.4 ms\n",
      "Wall time: 344 ms\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "train_data_location = 's3://sagemaker-sample-data-{}/mxnet/mnist/train'.format(region)\n",
    "test_data_location = 's3://sagemaker-sample-data-{}/mxnet/mnist/test'.format(region)\n",
    "\n",
    "mnist_estimator.fit({'train': train_data_location, 'test': test_data_location}, wait=False)\n",
    "\n",
    "training_job_name = mnist_estimator.latest_training_job.name\n",
    "print('training_job_name:  {}'.format(training_job_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-06 18:54:09 Starting - Launching requested ML instances."
     ]
    }
   ],
   "source": [
    "from sagemaker.mxnet import MXNet\n",
    "\n",
    "mnist_estimator = MXNet.attach(training_job_name=training_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Invalid endpoint: https://s3.{region}.amazonaws.com\r\n"
     ]
    }
   ],
   "source": [
    "!aws --region {region} s3 ls --recursive {model_output_path}/{training_job_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an inference Endpoint\n",
    "\n",
    "After training, we use the ``MXNet estimator`` object to build and deploy an ``MXNetPredictor``. This creates a Sagemaker **Endpoint** -- a hosted prediction service that we can use to perform inference. \n",
    "\n",
    "The arguments to the ``deploy`` function allow us to set the number and type of instances that will be used for the Endpoint. These do not need to be the same as the values we used for the training job. For example, you can train a model on a set of GPU-based instances, and then deploy the Endpoint to a fleet of CPU-based instances. Here we will deploy the model to a single ``ml.m4.xlarge`` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "predictor = mnist_estimator.deploy(initial_instance_count=1,\n",
    "                                   instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The request handling behavior of the Endpoint is determined by the ``mnist_mxnet.py`` script. In this case, the script doesn't include any request handling functions, so the Endpoint will use the default handlers provided by SageMaker. These default handlers allow us to perform inference on input data encoded as a multi-dimensional JSON array.\n",
    "\n",
    "### Making an inference request\n",
    "\n",
    "Now that our Endpoint is deployed and we have a ``predictor`` object, we can use it to classify handwritten digits.\n",
    "\n",
    "To see inference in action, draw a digit in the image box below. The pixel data from your drawing will be loaded into a ``data`` variable in this notebook. \n",
    "\n",
    "*Note: after drawing the image, you'll need to move to the next notebook cell.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(open(\"input.html\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the ``predictor`` object to classify the handwritten digit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response = predictor.predict(data)\n",
    "print('Raw prediction result:')\n",
    "response = response[0]\n",
    "print(response)\n",
    "\n",
    "labeled_predictions = list(zip(range(10), response))\n",
    "print('Labeled predictions: ')\n",
    "print(labeled_predictions)\n",
    "\n",
    "labeled_predictions.sort(key=lambda label_and_prob: 1.0 - label_and_prob[1])\n",
    "print('Most likely answer: {}'.format(labeled_predictions[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# (Optional) Delete the Endpoint\n",
    "\n",
    "After you have finished with this example, remember to delete the prediction endpoint to release the instance(s) associated with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Endpoint name: \" + predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
