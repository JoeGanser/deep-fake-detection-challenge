{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#########################\n",
    "# Make sure you are using the `conda_python3` Jupyter Kernel for SageMaker!\n",
    "## We will install the necessary libraries.\n",
    "\n",
    "#########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Training and Serving in SageMaker \"Script Mode\"\n",
    "\n",
    "Script mode is a training script format for TensorFlow that lets you execute any TensorFlow training script in SageMaker with minimal modification. The [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk) handles transferring your script to a SageMaker training instance. On the training instance, SageMaker's native TensorFlow support sets up training-related environment variables and executes your training script. In this tutorial, we use the SageMaker Python SDK to launch a training job and deploy the trained model.\n",
    "\n",
    "Script mode supports training with a Python script, a Python module, or a shell script. In this example, we use a Python script to train a classification model on the [MNIST dataset](http://yann.lecun.com/exdb/mnist/). In this example, we will show how easily you can train a SageMaker using TensorFlow 1.x and TensorFlow 2.x scripts with SageMaker Python SDK. In addition, this notebook demonstrates how to perform real time inference with the [SageMaker TensorFlow Serving container](https://github.com/aws/sagemaker-tensorflow-serving-container). The TensorFlow Serving container is the default inference method for script mode. For full documentation on the TensorFlow Serving container, please visit [here](https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/tensorflow/deploying_tensorflow_serving.rst).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the environment\n",
    "\n",
    "Let's start by setting up the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stepfunctions\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/bd/3a12e95691a81620bd24535b099640deb0e153567e3d62cd113d3bdbf69a/stepfunctions-1.0.0.3.tar.gz (57kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 24.2MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement not upgraded as not directly required: sagemaker>=1.42.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from stepfunctions) (1.49.0)\n",
      "Requirement not upgraded as not directly required: boto3>=1.9.213 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from stepfunctions) (1.10.45)\n",
      "Requirement not upgraded as not directly required: pyyaml in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from stepfunctions) (3.12)\n",
      "Requirement not upgraded as not directly required: numpy>=1.9.0 in /home/ec2-user/.local/lib/python3.6/site-packages (from sagemaker>=1.42.8->stepfunctions) (1.18.0)\n",
      "Requirement not upgraded as not directly required: protobuf>=3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker>=1.42.8->stepfunctions) (3.11.2)\n",
      "Requirement not upgraded as not directly required: scipy>=0.19.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker>=1.42.8->stepfunctions) (1.4.1)\n",
      "Requirement not upgraded as not directly required: protobuf3-to-dict>=0.1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker>=1.42.8->stepfunctions) (0.1.5)\n",
      "Requirement not upgraded as not directly required: requests<2.21,>=2.20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker>=1.42.8->stepfunctions) (2.20.1)\n",
      "Requirement not upgraded as not directly required: smdebug-rulesconfig==0.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from sagemaker>=1.42.8->stepfunctions) (0.1.2)\n",
      "Requirement not upgraded as not directly required: s3transfer<0.3.0,>=0.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3>=1.9.213->stepfunctions) (0.2.1)\n",
      "Requirement not upgraded as not directly required: botocore<1.14.0,>=1.13.45 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3>=1.9.213->stepfunctions) (1.13.45)\n",
      "Requirement not upgraded as not directly required: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3>=1.9.213->stepfunctions) (0.9.4)\n",
      "Requirement not upgraded as not directly required: six>=1.9 in /home/ec2-user/.local/lib/python3.6/site-packages (from protobuf>=3.1->sagemaker>=1.42.8->stepfunctions) (1.13.0)\n",
      "Requirement not upgraded as not directly required: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from protobuf>=3.1->sagemaker>=1.42.8->stepfunctions) (42.0.2)\n",
      "Requirement not upgraded as not directly required: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<2.21,>=2.20.0->sagemaker>=1.42.8->stepfunctions) (2019.11.28)\n",
      "Requirement not upgraded as not directly required: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<2.21,>=2.20.0->sagemaker>=1.42.8->stepfunctions) (2.7)\n",
      "Requirement not upgraded as not directly required: urllib3<1.25,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<2.21,>=2.20.0->sagemaker>=1.42.8->stepfunctions) (1.24.3)\n",
      "Requirement not upgraded as not directly required: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<2.21,>=2.20.0->sagemaker>=1.42.8->stepfunctions) (3.0.4)\n",
      "Requirement not upgraded as not directly required: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<1.14.0,>=1.13.45->boto3>=1.9.213->stepfunctions) (2.8.1)\n",
      "Requirement not upgraded as not directly required: docutils<0.16,>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<1.14.0,>=1.13.45->boto3>=1.9.213->stepfunctions) (0.15.2)\n",
      "Building wheels for collected packages: stepfunctions\n",
      "  Running setup.py bdist_wheel for stepfunctions ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/39/1c/08/e6d86db2311997594514838ae1271eb66f3ef709029770e7a6\n",
      "Successfully built stepfunctions\n",
      "\u001b[31mawscli 1.16.283 has requirement botocore==1.13.19, but you'll have botocore 1.13.45 which is incompatible.\u001b[0m\n",
      "Installing collected packages: stepfunctions\n",
      "Successfully installed stepfunctions-1.0.0.3\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade stepfunctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install SageMaker Python SDK with TensorFlow 2.x Support (>1.49)\n",
    "_Note:  Ignore Warnings and Errors Below_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sagemaker\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/23/b307e086945faac6365f22bf59298ceb5afcc93d0d5a59fc218220ec5767/sagemaker-1.49.0.tar.gz (291kB)\n",
      "\u001b[K    100% |████████████████████████████████| 296kB 48.4MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting boto3>=1.10.32 (from sagemaker)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/01/1c749dc1bca8dda969f5fe0ba16fa6d24c6bd96572d118f790773c54a636/boto3-1.10.45-py2.py3-none-any.whl (128kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 62.2MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.9.0 (from sagemaker)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/e6/45f71bd24f4e37629e9db5fb75caab919507deae6a5a257f9e4685a5f931/numpy-1.18.0-cp36-cp36m-manylinux1_x86_64.whl (20.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 20.1MB 71.6MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting protobuf>=3.1 (from sagemaker)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/ac/838c8c8a5f33a58132dd2ad2a30329f6ae1614a9f56ffb79eaaf71a9d156/protobuf-3.11.2-cp36-cp36m-manylinux1_x86_64.whl (1.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.3MB 71.8MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=0.19.0 (from sagemaker)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dc/29/162476fd44203116e7980cfbd9352eef9db37c49445d1fec35509022f6aa/scipy-1.4.1-cp36-cp36m-manylinux1_x86_64.whl (26.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 26.1MB 57.7MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting protobuf3-to-dict>=0.1.5 (from sagemaker)\n",
      "  Downloading https://files.pythonhosted.org/packages/6b/55/522bb43539fed463275ee803d79851faaebe86d17e7e3dbc89870d0322b9/protobuf3-to-dict-0.1.5.tar.gz\n",
      "Collecting requests<2.21,>=2.20.0 (from sagemaker)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/17/5cbb026005115301a8fb2f9b0e3e8d32313142fe8b617070e7baad20554f/requests-2.20.1-py2.py3-none-any.whl (57kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 50.3MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting smdebug-rulesconfig==0.1.2 (from sagemaker)\n",
      "  Downloading https://files.pythonhosted.org/packages/36/08/b0d1d30f5c1e11a2d12af3b940cf5673dc5bbb67517d815807ae855abc5e/smdebug_rulesconfig-0.1.2-py2.py3-none-any.whl\n",
      "Collecting botocore<1.14.0,>=1.13.45 (from boto3>=1.10.32->sagemaker)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/22/9f8201d900956e57a9811e1b1c91c9f76c87487c76f636c2df1ce8379c38/botocore-1.13.45-py2.py3-none-any.whl (5.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 5.9MB 68.4MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1 (from boto3>=1.10.32->sagemaker)\n",
      "  Downloading https://files.pythonhosted.org/packages/83/94/7179c3832a6d45b266ddb2aac329e101367fbdb11f425f13771d27f225bb/jmespath-0.9.4-py2.py3-none-any.whl\n",
      "Collecting s3transfer<0.3.0,>=0.2.0 (from boto3>=1.10.32->sagemaker)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/8a/1fc3dba0c4923c2a76e1ff0d52b305c44606da63f718d14d3231e21c51b0/s3transfer-0.2.1-py2.py3-none-any.whl (70kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 54.2MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting setuptools (from protobuf>=3.1->sagemaker)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/28/c45d8b54c1339f9644b87663945e54a8503cfef59cf0f65b3ff5dd17cf64/setuptools-42.0.2-py2.py3-none-any.whl (583kB)\n",
      "\u001b[K    100% |████████████████████████████████| 583kB 69.0MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting six>=1.9 (from protobuf>=3.1->sagemaker)\n",
      "  Downloading https://files.pythonhosted.org/packages/65/26/32b8464df2a97e6dd1b656ed26b2c194606c16fe163c695a992b36c11cdf/six-1.13.0-py2.py3-none-any.whl\n",
      "Collecting certifi>=2017.4.17 (from requests<2.21,>=2.20.0->sagemaker)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/63/df50cac98ea0d5b006c55a399c3bf1db9da7b5a24de7890bc9cfd5dd9e99/certifi-2019.11.28-py2.py3-none-any.whl (156kB)\n",
      "\u001b[K    100% |████████████████████████████████| 163kB 72.8MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting urllib3<1.25,>=1.21.1 (from requests<2.21,>=2.20.0->sagemaker)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/11/525b02e4acc0c747de8b6ccdab376331597c569c42ea66ab0a1dbd36eca2/urllib3-1.24.3-py2.py3-none-any.whl (118kB)\n",
      "\u001b[K    100% |████████████████████████████████| 122kB 66.1MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting chardet<3.1.0,>=3.0.2 (from requests<2.21,>=2.20.0->sagemaker)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl (133kB)\n",
      "\u001b[K    100% |████████████████████████████████| 143kB 56.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting idna<2.8,>=2.5 (from requests<2.21,>=2.20.0->sagemaker)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4b/2a/0276479a4b3caeb8a8c1af2f8e4355746a97fab05a372e4a2c6a6b876165/idna-2.7-py2.py3-none-any.whl (58kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 49.6MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting docutils<0.16,>=0.10 (from botocore<1.14.0,>=1.13.45->boto3>=1.10.32->sagemaker)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/cd/a6aa959dca619918ccb55023b4cb151949c64d4d5d55b3f4ffd7eee0c6e8/docutils-0.15.2-py3-none-any.whl (547kB)\n",
      "\u001b[K    100% |████████████████████████████████| 552kB 65.3MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" (from botocore<1.14.0,>=1.13.45->boto3>=1.10.32->sagemaker)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl (227kB)\n",
      "\u001b[K    100% |████████████████████████████████| 235kB 73.5MB/s ta 0:00:01\n",
      "\u001b[31mawscli 1.16.283 has requirement botocore==1.13.19, but you'll have botocore 1.13.45 which is incompatible.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: docutils, six, python-dateutil, urllib3, jmespath, botocore, s3transfer, boto3, numpy, setuptools, protobuf, scipy, protobuf3-to-dict, certifi, chardet, idna, requests, smdebug-rulesconfig, sagemaker\n",
      "  Running setup.py install for protobuf3-to-dict ... \u001b[?25ldone\n",
      "\u001b[?25h  Running setup.py install for sagemaker ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed boto3-1.10.45 botocore-1.13.45 certifi-2019.11.28 chardet-3.0.4 docutils-0.15.2 idna-2.7 jmespath-0.9.4 numpy-1.18.0 protobuf-3.11.2 protobuf3-to-dict-0.1.5 python-dateutil-2.8.1 requests-2.20.1 s3transfer-0.2.1 sagemaker-1.49.0 scipy-1.4.1 setuptools-42.0.2 six-1.13.0 smdebug-rulesconfig-0.1.2 urllib3-1.24.3\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sagemaker --upgrade --ignore-installed --no-cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.0.0b1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/6c/2c9a5c4d095c63c2fb37d20def0e4f92685f7aee9243d6aae25862694fd1/tensorflow-2.0.0b1-cp36-cp36m-manylinux1_x86_64.whl (87.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 87.9MB 69.1MB/s ta 0:00:01  0% |▎                               | 870kB 49.0MB/s eta 0:00:02    52% |████████████████▉               | 46.3MB 47.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wheel>=0.26 (from tensorflow==2.0.0b1)\n",
      "  Downloading https://files.pythonhosted.org/packages/00/83/b4a77d044e78ad1a45610eb88f745be2fd2c6d658f9798a15e384b7d57c9/wheel-0.33.6-py2.py3-none-any.whl\n",
      "Collecting gast>=0.2.0 (from tensorflow==2.0.0b1)\n",
      "  Downloading https://files.pythonhosted.org/packages/1f/04/4e36c33f8eb5c5b6c622a1f4859352a6acca7ab387257d4b3c191d23ec1d/gast-0.3.2.tar.gz\n",
      "Collecting protobuf>=3.6.1 (from tensorflow==2.0.0b1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/ac/838c8c8a5f33a58132dd2ad2a30329f6ae1614a9f56ffb79eaaf71a9d156/protobuf-3.11.2-cp36-cp36m-manylinux1_x86_64.whl (1.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.3MB 76.1MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 (from tensorflow==2.0.0b1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/dd/99c47dd007dcf10d63fd895611b063732646f23059c618a373e85019eb0e/tf_estimator_nightly-1.14.0.dev2019060501-py2.py3-none-any.whl (496kB)\n",
      "\u001b[K    100% |████████████████████████████████| 501kB 75.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1.0 (from tensorflow==2.0.0b1)\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting absl-py>=0.7.0 (from tensorflow==2.0.0b1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/53/9243c600e047bd4c3df9e69cfabc1e8004a82cac2e0c484580a78a94ba2a/absl-py-0.9.0.tar.gz (104kB)\n",
      "\u001b[K    100% |████████████████████████████████| 112kB 69.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting wrapt>=1.11.1 (from tensorflow==2.0.0b1)\n",
      "  Downloading https://files.pythonhosted.org/packages/23/84/323c2415280bc4fc880ac5050dddfb3c8062c2552b34c2e512eb4aa68f79/wrapt-1.11.2.tar.gz\n",
      "Collecting astor>=0.6.0 (from tensorflow==2.0.0b1)\n",
      "  Downloading https://files.pythonhosted.org/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl\n",
      "Collecting keras-applications>=1.0.6 (from tensorflow==2.0.0b1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 55.4MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing>=1.0.5 (from tensorflow==2.0.0b1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 62.9MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting grpcio>=1.8.6 (from tensorflow==2.0.0b1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/9b/ba5d094f979325fdba696bafa9ee23cc50b8fc60481e3d2a9e13d76817dc/grpcio-1.26.0-cp36-cp36m-manylinux1_x86_64.whl (2.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.5MB 70.6MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting tb-nightly<1.14.0a20190604,>=1.14.0a20190603 (from tensorflow==2.0.0b1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/96/571b875cd81dda9d5dfa1422a4f9d749e67c0a8d4f4f0b33a4e5f5f35e27/tb_nightly-1.14.0a20190603-py3-none-any.whl (3.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.1MB 67.9MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting six>=1.10.0 (from tensorflow==2.0.0b1)\n",
      "  Downloading https://files.pythonhosted.org/packages/65/26/32b8464df2a97e6dd1b656ed26b2c194606c16fe163c695a992b36c11cdf/six-1.13.0-py2.py3-none-any.whl\n",
      "Collecting google-pasta>=0.1.6 (from tensorflow==2.0.0b1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/fd/1e86bc4837cc9a3a5faf3db9b1854aa04ad35b5f381f9648fbe81a6f94e4/google_pasta-0.1.8-py3-none-any.whl (57kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 57.0MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting numpy<2.0,>=1.14.5 (from tensorflow==2.0.0b1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/e6/45f71bd24f4e37629e9db5fb75caab919507deae6a5a257f9e4685a5f931/numpy-1.18.0-cp36-cp36m-manylinux1_x86_64.whl (20.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 20.1MB 46.7MB/s ta 0:00:01    80% |█████████████████████████▊      | 16.2MB 55.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting setuptools (from protobuf>=3.6.1->tensorflow==2.0.0b1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/28/c45d8b54c1339f9644b87663945e54a8503cfef59cf0f65b3ff5dd17cf64/setuptools-42.0.2-py2.py3-none-any.whl (583kB)\n",
      "\u001b[K    100% |████████████████████████████████| 583kB 71.7MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting h5py (from keras-applications>=1.0.6->tensorflow==2.0.0b1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/06/cafdd44889200e5438b897388f3075b52a8ef01f28a17366d91de0fa2d05/h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.9MB 55.6MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting werkzeug>=0.11.15 (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0b1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/42/3aeda98f96e85fd26180534d36570e4d18108d62ae36f87694b476b83d6f/Werkzeug-0.16.0-py2.py3-none-any.whl (327kB)\n",
      "\u001b[K    100% |████████████████████████████████| 327kB 59.3MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8 (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0b1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 42.3MB/s ta 0:00:01\n",
      "\u001b[31mawscli 1.16.283 has requirement botocore==1.13.19, but you'll have botocore 1.13.45 which is incompatible.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: wheel, gast, setuptools, six, protobuf, tf-estimator-nightly, termcolor, absl-py, wrapt, astor, numpy, h5py, keras-applications, keras-preprocessing, grpcio, werkzeug, markdown, tb-nightly, google-pasta, tensorflow\n",
      "\u001b[33m  The script wheel is installed in '/home/ec2-user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "  Running setup.py install for gast ... \u001b[?25ldone\n",
      "\u001b[?25h  Running setup.py install for termcolor ... \u001b[?25ldone\n",
      "\u001b[?25h  Running setup.py install for absl-py ... \u001b[?25ldone\n",
      "\u001b[?25h  Running setup.py install for wrapt ... \u001b[?25ldone\n",
      "\u001b[33m  The scripts f2py, f2py3 and f2py3.6 are installed in '/home/ec2-user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  The script markdown_py is installed in '/home/ec2-user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  The script tensorboard is installed in '/home/ec2-user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  The scripts freeze_graph, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/home/ec2-user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[?25hSuccessfully installed absl-py-0.9.0 astor-0.8.1 gast-0.3.2 google-pasta-0.1.8 grpcio-1.26.0 h5py-2.10.0 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.1.1 numpy-1.18.0 protobuf-3.11.2 setuptools-42.0.2 six-1.13.0 tb-nightly-1.14.0a20190603 tensorflow-2.0.0b1 termcolor-1.1.0 tf-estimator-nightly-1.14.0.dev2019060501 werkzeug-0.16.0 wheel-0.33.6 wrapt-1.11.2\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.0.0b1 --upgrade --ignore-installed --no-cache --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                            Version             \n",
      "---------------------------------- --------------------\n",
      "absl-py                            0.9.0               \n",
      "alabaster                          0.7.10              \n",
      "anaconda-client                    1.6.14              \n",
      "anaconda-project                   0.8.2               \n",
      "asn1crypto                         0.24.0              \n",
      "astor                              0.8.1               \n",
      "astroid                            1.6.3               \n",
      "astropy                            3.0.2               \n",
      "attrs                              18.1.0              \n",
      "Automat                            0.3.0               \n",
      "autovizwidget                      0.13.1              \n",
      "awscli                             1.16.283            \n",
      "Babel                              2.5.3               \n",
      "backcall                           0.1.0               \n",
      "backports.shutil-get-terminal-size 1.0.0               \n",
      "bcrypt                             3.1.7               \n",
      "beautifulsoup4                     4.6.0               \n",
      "bitarray                           0.8.1               \n",
      "bkcharts                           0.2                 \n",
      "blaze                              0.11.3              \n",
      "bleach                             2.1.3               \n",
      "bokeh                              1.0.4               \n",
      "boto                               2.48.0              \n",
      "boto3                              1.10.45             \n",
      "botocore                           1.13.45             \n",
      "Bottleneck                         1.2.1               \n",
      "cached-property                    1.5.1               \n",
      "certifi                            2019.11.28          \n",
      "cffi                               1.11.5              \n",
      "characteristic                     14.3.0              \n",
      "chardet                            3.0.4               \n",
      "click                              6.7                 \n",
      "cloudpickle                        0.5.3               \n",
      "clyent                             1.2.2               \n",
      "colorama                           0.3.9               \n",
      "contextlib2                        0.5.5               \n",
      "cryptography                       2.8                 \n",
      "cycler                             0.10.0              \n",
      "Cython                             0.28.4              \n",
      "cytoolz                            0.9.0.1             \n",
      "dask                               0.17.5              \n",
      "datashape                          0.5.4               \n",
      "decorator                          4.3.0               \n",
      "defusedxml                         0.6.0               \n",
      "distributed                        1.21.8              \n",
      "docker                             3.7.3               \n",
      "docker-compose                     1.24.1              \n",
      "docker-pycreds                     0.4.0               \n",
      "dockerpty                          0.4.1               \n",
      "docopt                             0.6.2               \n",
      "docutils                           0.15.2              \n",
      "entrypoints                        0.2.3               \n",
      "environment-kernels                1.1.1               \n",
      "et-xmlfile                         1.0.1               \n",
      "fabric                             2.5.0               \n",
      "fastcache                          1.0.2               \n",
      "filelock                           3.0.4               \n",
      "Flask                              1.0.2               \n",
      "Flask-Cors                         3.0.4               \n",
      "gast                               0.3.2               \n",
      "gevent                             1.3.0               \n",
      "glob2                              0.6                 \n",
      "gmpy2                              2.0.8               \n",
      "google-pasta                       0.1.8               \n",
      "greenlet                           0.4.13              \n",
      "grpcio                             1.26.0              \n",
      "h5py                               2.10.0              \n",
      "hdijupyterutils                    0.13.1              \n",
      "heapdict                           1.0.0               \n",
      "html5lib                           1.0.1               \n",
      "idna                               2.7                 \n",
      "imageio                            2.3.0               \n",
      "imagesize                          1.0.0               \n",
      "invoke                             1.3.0               \n",
      "ipykernel                          4.8.2               \n",
      "ipyparallel                        6.2.2               \n",
      "ipython                            6.4.0               \n",
      "ipython-genutils                   0.2.0               \n",
      "ipywidgets                         7.4.0               \n",
      "isort                              4.3.4               \n",
      "itsdangerous                       0.24                \n",
      "jdcal                              1.4                 \n",
      "jedi                               0.12.0              \n",
      "Jinja2                             2.10                \n",
      "jmespath                           0.9.4               \n",
      "jsonschema                         2.6.0               \n",
      "jupyter                            1.0.0               \n",
      "jupyter-client                     5.2.3               \n",
      "jupyter-console                    5.2.0               \n",
      "jupyter-core                       4.4.0               \n",
      "jupyterlab                         0.32.1              \n",
      "jupyterlab-launcher                0.10.5              \n",
      "Keras-Applications                 1.0.8               \n",
      "Keras-Preprocessing                1.1.0               \n",
      "kiwisolver                         1.0.1               \n",
      "lazy-object-proxy                  1.3.1               \n",
      "llvmlite                           0.23.1              \n",
      "locket                             0.2.0               \n",
      "lxml                               4.2.1               \n",
      "Markdown                           3.1.1               \n",
      "MarkupSafe                         1.0                 \n",
      "matplotlib                         3.0.3               \n",
      "mccabe                             0.6.1               \n",
      "mistune                            0.8.3               \n",
      "mkl-fft                            1.0.0               \n",
      "mkl-random                         1.0.1               \n",
      "mock                               3.0.5               \n",
      "more-itertools                     4.1.0               \n",
      "mpmath                             1.0.0               \n",
      "msgpack                            0.6.0               \n",
      "msgpack-python                     0.5.6               \n",
      "multipledispatch                   0.5.0               \n",
      "nb-conda                           2.2.1               \n",
      "nb-conda-kernels                   2.2.2               \n",
      "nbconvert                          5.4.1               \n",
      "nbformat                           4.4.0               \n",
      "networkx                           2.1                 \n",
      "nltk                               3.3                 \n",
      "nose                               1.3.7               \n",
      "notebook                           5.5.0               \n",
      "numba                              0.38.0              \n",
      "numexpr                            2.6.5               \n",
      "numpy                              1.18.0              \n",
      "numpydoc                           0.8.0               \n",
      "odo                                0.5.1               \n",
      "olefile                            0.45.1              \n",
      "openpyxl                           2.5.3               \n",
      "packaging                          17.1                \n",
      "pandas                             0.24.2              \n",
      "pandocfilters                      1.4.2               \n",
      "paramiko                           2.6.0               \n",
      "parso                              0.2.0               \n",
      "partd                              0.3.8               \n",
      "path.py                            11.0.1              \n",
      "pathlib2                           2.3.2               \n",
      "patsy                              0.5.0               \n",
      "pep8                               1.7.1               \n",
      "pexpect                            4.5.0               \n",
      "pickleshare                        0.7.4               \n",
      "Pillow                             6.2.1               \n",
      "pip                                10.0.1              \n",
      "pkginfo                            1.4.2               \n",
      "plotly                             4.2.1               \n",
      "pluggy                             0.6.0               \n",
      "ply                                3.11                \n",
      "prompt-toolkit                     1.0.15              \n",
      "protobuf                           3.11.2              \n",
      "protobuf3-to-dict                  0.1.5               \n",
      "psutil                             5.4.5               \n",
      "psycopg2                           2.7.5               \n",
      "ptyprocess                         0.5.2               \n",
      "py                                 1.5.3               \n",
      "py4j                               0.10.7              \n",
      "pyasn1                             0.4.8               \n",
      "pycodestyle                        2.4.0               \n",
      "pycosat                            0.6.3               \n",
      "pycparser                          2.18                \n",
      "pycrypto                           2.6.1               \n",
      "pycurl                             7.43.0.1            \n",
      "pyflakes                           1.6.0               \n",
      "pygal                              2.4.0               \n",
      "Pygments                           2.2.0               \n",
      "pykerberos                         1.2.1               \n",
      "pylint                             1.8.4               \n",
      "PyNaCl                             1.3.0               \n",
      "pyodbc                             4.0.23              \n",
      "pyOpenSSL                          18.0.0              \n",
      "pyparsing                          2.2.0               \n",
      "PySocks                            1.6.8               \n",
      "pyspark                            2.3.2               \n",
      "pytest                             3.5.1               \n",
      "pytest-arraydiff                   0.2                 \n",
      "pytest-astropy                     0.3.0               \n",
      "pytest-doctestplus                 0.1.3               \n",
      "pytest-openfiles                   0.3.0               \n",
      "pytest-remotedata                  0.2.1               \n",
      "python-dateutil                    2.8.1               \n",
      "pytz                               2018.4              \n",
      "PyWavelets                         0.5.2               \n",
      "PyYAML                             3.12                \n",
      "pyzmq                              17.0.0              \n",
      "QtAwesome                          0.4.4               \n",
      "qtconsole                          4.3.1               \n",
      "QtPy                               1.4.1               \n",
      "requests                           2.20.1              \n",
      "requests-kerberos                  0.12.0              \n",
      "retrying                           1.3.3               \n",
      "rope                               0.10.7              \n",
      "rsa                                3.4.2               \n",
      "ruamel-yaml                        0.15.35             \n",
      "s3fs                               0.1.5               \n",
      "s3transfer                         0.2.1               \n",
      "sagemaker                          1.49.0              \n",
      "sagemaker-pyspark                  1.2.6               \n",
      "scikit-image                       0.13.1              \n",
      "scikit-learn                       0.20.3              \n",
      "scipy                              1.4.1               \n",
      "seaborn                            0.8.1               \n",
      "Send2Trash                         1.5.0               \n",
      "setuptools                         42.0.2              \n",
      "simplegeneric                      0.8.1               \n",
      "singledispatch                     3.4.0.3             \n",
      "six                                1.13.0              \n",
      "smdebug-rulesconfig                0.1.2               \n",
      "snowballstemmer                    1.2.1               \n",
      "sortedcollections                  0.6.1               \n",
      "sortedcontainers                   1.5.10              \n",
      "sparkmagic                         0.12.5              \n",
      "Sphinx                             1.7.4               \n",
      "sphinxcontrib-websupport           1.0.1               \n",
      "spyder                             3.2.8               \n",
      "SQLAlchemy                         1.2.11              \n",
      "statsmodels                        0.9.0               \n",
      "stepfunctions                      1.0.0.3             \n",
      "sympy                              1.1.1               \n",
      "tables                             3.4.3               \n",
      "tb-nightly                         1.14.0a20190603     \n",
      "tblib                              1.3.2               \n",
      "tensorflow                         2.0.0b1             \n",
      "termcolor                          1.1.0               \n",
      "terminado                          0.8.1               \n",
      "testpath                           0.3.1               \n",
      "texttable                          0.9.1               \n",
      "tf-estimator-nightly               1.14.0.dev2019060501\n",
      "toolz                              0.9.0               \n",
      "torch                              1.3.1               \n",
      "torchvision                        0.4.2               \n",
      "tornado                            5.0.2               \n",
      "traitlets                          4.3.2               \n",
      "typing                             3.6.4               \n",
      "unicodecsv                         0.14.1              \n",
      "urllib3                            1.24.3              \n",
      "wcwidth                            0.1.7               \n",
      "webencodings                       0.5.1               \n",
      "websocket-client                   0.56.0              \n",
      "Werkzeug                           0.16.0              \n",
      "wheel                              0.33.6              \n",
      "widgetsnbextension                 3.4.2               \n",
      "wrapt                              1.11.2              \n",
      "xlrd                               1.1.0               \n",
      "XlsxWriter                         1.0.4               \n",
      "xlwt                               1.3.0               \n",
      "zict                               0.1.3               \n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restart the Kernel to Recognize New Dependencies Above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display_html\n",
    "display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\", raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a policy to your SageMaker role in IAM\n",
    "\n",
    "**If you are running this notebook on an Amazon SageMaker notebook instance**, the IAM role assumed by your notebook instance needs permission to create and run workflows in AWS Step Functions. To provide this permission to the role, do the following.\n",
    "\n",
    "1. Open the Amazon [SageMaker console](https://console.aws.amazon.com/sagemaker/). \n",
    "2. Select **Notebook instances** and choose the name of your notebook instance\n",
    "3. Under **Permissions and encryption** select the role ARN to view the role on the IAM console\n",
    "4. Choose **Attach policies** and search for `AWSStepFunctionsFullAccess`.\n",
    "5. Select the check box next to `AWSStepFunctionsFullAccess` and choose **Attach policy**\n",
    "\n",
    "If you are running this notebook in a local environment, the SDK will use your configured AWS CLI configuration. For more information, see [Configuring the AWS CLI](https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html).\n",
    "\n",
    "Next, create an execution role in IAM for Step Functions. \n",
    "\n",
    "### Create an execution role for Step Functions\n",
    "\n",
    "You need an execution role so that you can create and execute workflows in Step Functions.\n",
    "\n",
    "1. Go to the [IAM console](https://console.aws.amazon.com/iam/)\n",
    "2. Select **Roles** and then **Create role**.\n",
    "3. Under **Choose the service that will use this role** select **Step Functions**\n",
    "4. Choose **Next** until you can enter a **Role name**\n",
    "5. Enter a name such as `StepFunctionsWorkflowExecutionRole` and then select **Create role**\n",
    "\n",
    "\n",
    "Attach a policy to the role you created. The following steps attach a policy that provides full access to Step Functions, however as a good practice you should only provide access to the resources you need.  \n",
    "\n",
    "1. Under the **Permissions** tab, click **Add inline policy**\n",
    "2. Enter the following in the **JSON** tab\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"sagemaker:CreateTransformJob\",\n",
    "                \"sagemaker:DescribeTransformJob\",\n",
    "                \"sagemaker:StopTransformJob\",\n",
    "                \"sagemaker:CreateTrainingJob\",\n",
    "                \"sagemaker:DescribeTrainingJob\",\n",
    "                \"sagemaker:StopTrainingJob\",\n",
    "                \"sagemaker:CreateHyperParameterTuningJob\",\n",
    "                \"sagemaker:DescribeHyperParameterTuningJob\",\n",
    "                \"sagemaker:StopHyperParameterTuningJob\",\n",
    "                \"sagemaker:CreateModel\",\n",
    "                \"sagemaker:CreateEndpointConfig\",\n",
    "                \"sagemaker:CreateEndpoint\",\n",
    "                \"sagemaker:DeleteEndpointConfig\",\n",
    "                \"sagemaker:DeleteEndpoint\",\n",
    "                \"sagemaker:UpdateEndpoint\",\n",
    "                \"sagemaker:ListTags\",\n",
    "                \"lambda:InvokeFunction\",\n",
    "                \"sqs:SendMessage\",\n",
    "                \"sns:Publish\",\n",
    "                \"ecs:RunTask\",\n",
    "                \"ecs:StopTask\",\n",
    "                \"ecs:DescribeTasks\",\n",
    "                \"dynamodb:GetItem\",\n",
    "                \"dynamodb:PutItem\",\n",
    "                \"dynamodb:UpdateItem\",\n",
    "                \"dynamodb:DeleteItem\",\n",
    "                \"batch:SubmitJob\",\n",
    "                \"batch:DescribeJobs\",\n",
    "                \"batch:TerminateJob\",\n",
    "                \"glue:StartJobRun\",\n",
    "                \"glue:GetJobRun\",\n",
    "                \"glue:GetJobRuns\",\n",
    "                \"glue:BatchStopJobRun\"\n",
    "            ],\n",
    "            \"Resource\": \"*\"\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"iam:PassRole\"\n",
    "            ],\n",
    "            \"Resource\": \"*\",\n",
    "            \"Condition\": {\n",
    "                \"StringEquals\": {\n",
    "                    \"iam:PassedToService\": \"sagemaker.amazonaws.com\"\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"events:PutTargets\",\n",
    "                \"events:PutRule\",\n",
    "                \"events:DescribeRule\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:events:*:*:rule/StepFunctionsGetEventsForSageMakerTrainingJobsRule\",\n",
    "                \"arn:aws:events:*:*:rule/StepFunctionsGetEventsForSageMakerTransformJobsRule\",\n",
    "                \"arn:aws:events:*:*:rule/StepFunctionsGetEventsForSageMakerTuningJobsRule\",\n",
    "                \"arn:aws:events:*:*:rule/StepFunctionsGetEventsForECSTaskRule\",\n",
    "                \"arn:aws:events:*:*:rule/StepFunctionsGetEventsForBatchJobsRule\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "3. Choose **Review policy** and give the policy a name such as `StepFunctionsWorkflowExecutionPolicy`\n",
    "4. Choose **Create policy**. You will be redirected to the details page for the role.\n",
    "5. Copy the **Role ARN** at the top of the **Summary**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the required modules & create the AWS SageMaker execution role\n",
    "\n",
    "Now import the required modules from the Step Functions SDK and AWS SageMaker, configure an S3 bucket, and get the AWS SageMaker execution role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "import stepfunctions\n",
    "import logging\n",
    "\n",
    "from stepfunctions.template.pipeline import TrainingPipeline\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "stepfunctions.set_stream_logger(level=logging.INFO)\n",
    "\n",
    "#bucket = sagemaker_session.default_bucket()\n",
    "#prefix = 'sagemaker/DEMO-tensorflow-mnist'\n",
    "\n",
    "# SageMaker Execution Role\n",
    "# You can use sagemaker.get_execution_role() if running inside sagemaker's notebook instance\n",
    "sagemaker_execution_role = sagemaker.get_execution_role() #Replace with ARN if not in an AWS SageMaker notebook\n",
    "\n",
    "# paste the StepFunctionsWorkflowExecutionRole ARN from above\n",
    "workflow_execution_role = \"arn:aws:iam::806570384721:role/StepFunctionsWorkflowExecutionRole\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the Service Execution Role and Region\n",
    "Get IAM role arn used to give training and hosting access to your data.  See the documentation for how to create these.  Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the `sagemaker.get_execution_role()` with a the appropriate full IAM role arn string(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoleARN:  arn:aws:iam::806570384721:role/service-role/AmazonSageMaker-ExecutionRole-20191201T115647\n",
      "\n",
      "Region:  us-east-1\n"
     ]
    }
   ],
   "source": [
    "#role = get_execution_role()\n",
    "print('RoleARN:  {}\\n'.format(sagemaker_execution_role))\n",
    "\n",
    "region = sagemaker_session.boto_session.region_name\n",
    "print('Region:  {}'.format(region))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data\n",
    "\n",
    "The MNIST dataset has been loaded to the public S3 buckets ``sagemaker-sample-data-<REGION>`` under the prefix ``tensorflow/mnist``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-sample-data-us-east-1/tensorflow/mnist\n"
     ]
    }
   ],
   "source": [
    "original_training_data_uri = 's3://sagemaker-sample-data-{}/tensorflow/mnist'.format(region)\n",
    "print(original_training_data_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy the Training Data to Your Notebook Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_data_path = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-sample-data-us-east-1/tensorflow/mnist/eval_labels.npy to data/eval_labels.npy\n",
      "download: s3://sagemaker-sample-data-us-east-1/tensorflow/mnist/train_labels.npy to data/train_labels.npy\n",
      "download: s3://sagemaker-sample-data-us-east-1/tensorflow/mnist/eval_data.npy to data/eval_data.npy\n",
      "download: s3://sagemaker-sample-data-us-east-1/tensorflow/mnist/train_data.npy to data/train_data.npy\n"
     ]
    }
   ],
   "source": [
    "!aws --region {region} s3 cp --recursive {original_training_data_uri} {local_data_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are four ``.npy`` file under this prefix:\n",
    "* ``train_data.npy``\n",
    "* ``eval_data.npy``\n",
    "* ``train_labels.npy``\n",
    "* ``eval_labels.npy``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_data.npy  eval_labels.npy\ttrain_data.npy\ttrain_labels.npy\n"
     ]
    }
   ],
   "source": [
    "!ls {local_data_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the Data to S3 for Distributed Training Across Many Workers\n",
    "We are going to use the `sagemaker.Session.upload_data` function to upload our datasets to an S3 location. The return value inputs identifies the location -- we will use later when we start the training job.\n",
    "\n",
    "This is S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as the Notebook Instance, training, and hosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = sagemaker_session.default_bucket()\n",
    "data_prefix = 'sagemaker/tensorflow-mnist/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-806570384721/sagemaker/tensorflow-mnist/data\n"
     ]
    }
   ],
   "source": [
    "training_data_uri = sagemaker_session.upload_data(path=local_data_path, bucket=bucket, key_prefix=data_prefix)\n",
    "print(training_data_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-27 16:14:35   31360128 sagemaker/tensorflow-mnist/data/eval_data.npy\n",
      "2019-12-27 16:14:33      40128 sagemaker/tensorflow-mnist/data/eval_labels.npy\n",
      "2019-12-27 16:14:33  172480128 sagemaker/tensorflow-mnist/data/train_data.npy\n",
      "2019-12-27 16:14:36     220128 sagemaker/tensorflow-mnist/data/train_labels.npy\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls --recursive {training_data_uri}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "https://sagemaker.readthedocs.io/en/stable/using_tf.html#distributed-training\n",
    "\n",
    "This tutorial's training script was adapted from TensorFlow's official [CNN MNIST example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/layers/cnn_mnist.py). We have modified it to handle the ``model_dir`` parameter passed in by SageMaker. This is an S3 path which can be used for data sharing during distributed training and checkpointing and/or model persistence. We have also added an argument-parsing function to handle processing training-related variables.\n",
    "\n",
    "At the end of the training job we have added a step to export the trained model to the path stored in the environment variable ``SM_MODEL_DIR``, which always points to ``/opt/ml/model``. This is critical because SageMaker uploads all the model artifacts in this folder to S3 at end of training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./src/mnist_keras_tf2.py\n"
     ]
    }
   ],
   "source": [
    "!ls ./src/mnist_keras_tf2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add custom Python modules to the `src/requirements.txt` file.  They will automatically be installed - and made available to your training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Python dependencies go here..."
     ]
    }
   ],
   "source": [
    "!cat ./src/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Step Functions to run training in SageMaker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with SageMaker `TensorFlow` Estimator\n",
    "\n",
    "https://sagemaker.readthedocs.io/en/stable/using_tf.html#distributed-training\n",
    "\n",
    "The `sagemaker.tensorflow.TensorFlow` estimator handles locating the script mode container, uploading your script to a S3 location and creating a SageMaker training job. Let's call out a couple important parameters here:\n",
    "\n",
    "* `py_version` is set to `'py3'` to indicate that we are using script mode since legacy mode supports only Python 2. Though Python 2 will be deprecated soon, you can use script mode with Python 2 by setting `py_version` to `'py2'` and `script_mode` to `True`.\n",
    "\n",
    "* `distributions` is used to configure the distributed training setup. It's required only if you are doing distributed training either across a cluster of instances or across multiple GPUs. Here we are using parameter servers as the distributed training schema. SageMaker training jobs run on homogeneous clusters. To make parameter server more performant in the SageMaker setup, we run a parameter server on every instance in the cluster, so there is no need to specify the number of parameter servers to launch. Script mode also supports distributed training with [Horovod](https://github.com/horovod/horovod). You can find the full documentation on how to configure `distributions` [here](https://github.com/aws/sagemaker-python-sdk/tree/master/src/sagemaker/tensorflow#distributed-training). \n",
    "\n",
    "Notes:  \n",
    "* This example uses two(2) `ml.p3.2xlarge` instances.  You will likely need to request a SageMaker instance limit increase from Support before continuing.\n",
    "\n",
    "* Alternatively, you can specify `ml.c5.2xlarge` instead.\n",
    "\n",
    "* To recognize the `requirements.txt`, we must include `src/setup.py` per [this](https://github.com/aws/sagemaker-python-sdk/issues/911) GitHub issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "model_output_path = 's3://{}/sagemaker/tensorflow-mnist/training-runs'.format(bucket)\n",
    "\n",
    "mnist_estimator = TensorFlow(entry_point='mnist_keras_tf2.py',\n",
    "                             source_dir='./src',\n",
    "                             output_path=model_output_path,\n",
    "                             role=sagemaker_execution_role,\n",
    "                             train_instance_count=2,\n",
    "                             train_instance_type='ml.p3.2xlarge',\n",
    "                             framework_version='2.0.0',\n",
    "                             py_version='py3',\n",
    "                             distributions={'parameter_server': {'enabled': True}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a training pipeline with the Step Functions SDK\n",
    "\n",
    "A typical task for a data scientist is to train a model and deploy that model to an endpoint. Without the Step Functions SDK, this is a four step process on SageMaker that includes the following.\n",
    "\n",
    "1. Training the model\n",
    "2. Creating the model on SageMaker\n",
    "3. Creating an endpoint configuration\n",
    "4. Deploying the trained model to the configured endpoint\n",
    "\n",
    "The Step Functions SDK provides the [TrainingPipeline](https://aws-step-functions-data-science-sdk.readthedocs.io/en/latest/pipelines.html#stepfunctions.template.pipeline.train.TrainingPipeline) API to simplify this procedure. The following configures `pipeline` with the necessary parameters to define a training pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-806570384721/sagemaker/tensorflow-mnist/data\n",
      "s3://sagemaker-us-east-1-806570384721/sagemaker/tensorflow-mnist/training-runs\n"
     ]
    }
   ],
   "source": [
    "print(training_data_uri)\n",
    "print(model_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute '__framework_name__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-23cc1e7f4991>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mrole\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkflow_execution_role\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_data_uri\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0ms3_bucket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_output_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/stepfunctions/template/pipeline/train.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, estimator, role, inputs, s3_bucket, client, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'training-pipeline-{date}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_timestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefinition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_workflow_definition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_template\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_input_template\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefinition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/stepfunctions/template/pipeline/train.py\u001b[0m in \u001b[0;36mbuild_workflow_definition\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0minstance_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_instance_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         )\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/stepfunctions/steps/sagemaker.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, state_id, model, model_name, instance_type, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \"\"\"\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFrameworkModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstance_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrole\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrole\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ModelName'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/workflow/airflow.py\u001b[0m in \u001b[0;36mmodel_config\u001b[0;34m(instance_type, model, role, image)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msagemaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFrameworkModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0mcontainer_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_framework_container_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms3_operations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0mcontainer_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_container_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/workflow/airflow.py\u001b[0m in \u001b[0;36mprepare_framework_container_def\u001b[0;34m(model, instance_type, s3_operations)\u001b[0m\n\u001b[1;32m    519\u001b[0m         deploy_image = fw_utils.create_image_uri(\n\u001b[1;32m    520\u001b[0m             \u001b[0mregion_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__framework_name__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0minstance_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Model' object has no attribute '__framework_name__'"
     ]
    }
   ],
   "source": [
    "pipeline = TrainingPipeline(\n",
    "    estimator=mnist_estimator,\n",
    "    role=workflow_execution_role,\n",
    "    inputs=training_data_uri,\n",
    "    s3_bucket=model_output_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now view the workflow definition, and also visualize it as a graph. This workflow and graph represent your training pipeline.\n",
    "\n",
    "#### View the workflow definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-43bc93cad867>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefinition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "print(pipeline.workflow.definition.to_json(pretty=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the workflow graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.render_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and execute the pipeline on AWS Step Functions\n",
    "\n",
    "Create the pipeline in AWS Step Functions with [create](https://aws-step-functions-data-science-sdk.readthedocs.io/en/latest/workflow.html#stepfunctions.workflow.Workflow.create)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the workflow with [execute](https://aws-step-functions-data-science-sdk.readthedocs.io/en/latest/workflow.html#stepfunctions.workflow.Workflow.execute). A link will be provided after the following cell is executed. Following this link, you can monitor your pipeline execution on Step Functions' console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `fit` the Model (Approx. 15 mins)\n",
    "\n",
    "To start a training job, we call `estimator.fit(training_data_uri)`.\n",
    "\n",
    "An S3 location is used here as the input. `fit` creates a default channel named `'training'`, which points to this S3 location. In the training script we can then access the training data from the location stored in `SM_CHANNEL_TRAINING`. `fit` accepts other parameters, as well. See the API doc [here](https://sagemaker.readthedocs.io/en/stable/estimators.html#sagemaker.estimator.EstimatorBase.fit) for details.\n",
    "\n",
    "When training starts, the TensorFlow container executes `mnist_keras_tf2.py` by passing `hyperparameters` and `model_dir` from the estimator as script arguments. Because we didn't define either in this example, no hyperparameters are passed, and `model_dir` defaults to `s3://<DEFAULT_BUCKET>/<TRAINING_JOB_NAME>`, so the script execution is as follows:\n",
    "```bash\n",
    "python mnist_keras_tf2.py --model_dir s3://<DEFAULT_BUCKET>/<TRAINING_JOB_NAME>\n",
    "```\n",
    "When training is complete, the training job will upload the saved model for TensorFlow serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_estimator.fit(inputs=training_data_uri, wait=False)\n",
    "\n",
    "training_job_name = mnist_estimator.latest_training_job.name\n",
    "print('training_job_name:  {}'.format(training_job_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some time, or in a separate Python notebook, we can attach to the running job using the `training_job_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "mnist_estimator = TensorFlow.attach(training_job_name=training_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1:  Perform Batch Predictions Directly in the Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use TensorFlow Core to load the SavedModel from `model_output_path`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws --region {region} s3 ls --recursive {model_output_path}/{training_job_name}/output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws --region {region} s3 cp {model_output_path}/{training_job_name}/output/model.tar.gz ./model/model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ./model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!tar -xzvf ./model/model.tar.gz -C ./model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the signature of the model for prediction purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!saved_model_cli show --dir ./model/000000001 --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "loaded = tf.saved_model.load(export_dir='./model/000000001/')\n",
    "print(list(loaded.signatures.keys()))  # [\"serving_default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:  Finish this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2:  Perform Batch Predictions with a Batch Transform Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a [Batch Transformation Job](https://sagemaker.readthedocs.io/en/stable/using_tf.html#run-a-batch-transform-job) to run batch predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_output_uri = '{}/batch_output'.format(training_data_uri) # The location to store the results\n",
    "print(batch_output_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_transformer = mnist_estimator.transformer(instance_count=1, instance_type='ml.p3.2xlarge', output_path=batch_output_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:  We may need to use a custom data transformer to convert numpy format into json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_transformer.transform(data=training_data_uri, data_type='S3Prefix', content_type='text/csv', split_type='Line', wait=False)\n",
    "\n",
    "transform_job_name = mnist_transformer.latest_transformer_job.name\n",
    "print('transform_job_name:  {}'.format(transform_job_name))\n",
    "\n",
    "#print(batch_transform_job_name)\n",
    "#print(mnist_transformer.job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_transformer.attach(transform_job_name=transform_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws --region {region} s3 ls --recursive {batch_output_uri}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 3:  Create a SageMaker Endpoint and Perform REST-based Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the Trained Model to a SageMaker Endpoint (Approx. 10 mins)\n",
    "\n",
    "After training, we use the `TensorFlow` estimator object to build and deploy a `TensorFlowPredictor`.  This creates a Sagemaker Endpoint -- a hosted prediction service that we can use to perform inference.\n",
    "\n",
    "As mentioned above we have implementation of `model_fn` in the `tensorflow_mnist.py` script that is required. We are going to use default implementations of `input_fn`, `predict_fn`, `output_fn` and `transform_fm` defined in [sagemaker-tensorflow-containers](https://github.com/aws/sagemaker-tensorflow-containers).\n",
    "\n",
    "The `deploy()` method creates a SageMaker model, which is then deployed to an endpoint to serve prediction requests in real time.  We will use the TensorFlow Serving container for the endpoint, because we trained with script mode.  This serving container runs an implementation of a web server that is compatible with SageMaker hosting protocol.  The [Using your own inference code](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-inference-main.html) document explains how SageMaker runs inference containers.\n",
    "\n",
    "The arguments to the deploy function allow us to set the number and type of instances that will be used for the Endpoint.  These do not need to be the same as the values we used for the training job.  For example, you can train a model on a set of GPU-based instances, and then deploy the Endpoint to a fleet of CPU-based instances, but you need to make sure that you return or save your model as a cpu model similar to what we did in `mnist.py`.  Here we will deploy the model to a single `ml.p3.2xlarge` instance.  Alternatively, you can use a `ml.c5.2xlarge` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = mnist_estimator.deploy(initial_instance_count=1, instance_type='ml.p3.2xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke the Endpoint\n",
    "\n",
    "Let's download the training data and use that as input for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_data = np.load('{}/train_data.npy'.format(local_data_path))\n",
    "train_labels = np.load('{}/train_labels.npy'.format(local_data_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The formats of the input and the output data correspond directly to the request and response formats of the `Predict` method in the [TensorFlow Serving REST API](https://www.tensorflow.org/serving/api_rest). SageMaker's TensforFlow Serving endpoints can also accept additional input formats that are not part of the TensorFlow REST API, including the simplified JSON format, line-delimited JSON objects (\"jsons\" or \"jsonlines\"), and CSV data.\n",
    "\n",
    "In this example we are using a `numpy` array as input, which will be serialized into the simplified JSON format. In addition, TensorFlow Serving can also process multiple items at once as you can see in the following code. You can find the complete documentation on how to make predictions against a TensorFlow Serving SageMaker endpoint [here](https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/tensorflow/deploying_tensorflow_serving.rst#making-predictions-against-a-sagemaker-endpoint)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the prediction result from the TensorFlow 2.0 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictor.predict(train_data[:50])\n",
    "for i in range(0, 50):\n",
    "    prediction = predictions['predictions'][i]\n",
    "    label = train_labels[i]\n",
    "    print('prediction is {}, label is {}, matched: {}'.format(prediction, label, prediction == label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Let's delete the endpoint we just created to prevent incurring any extra costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist_estimator.delete_endpoint()\n",
    "\n",
    "sagemaker.Session().delete_endpoint(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
